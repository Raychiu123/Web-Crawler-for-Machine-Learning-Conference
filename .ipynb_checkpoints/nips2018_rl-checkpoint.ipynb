{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = urlopen(\"https://nips.cc/Conferences/2018/Schedule?type=Poster\").read().decode('utf-8')\n",
    "#print(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "div_tag = soup.find_all(\"div\", class_=\"maincardBody\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "a1 = []\n",
    "a2 = []\n",
    "a3 = []\n",
    "a4 = []\n",
    "a5 = []\n",
    "for i in div_tag:\n",
    "    if \"reinforce\" in i.string.lower():\n",
    "        #print(i.string)\n",
    "        a1.append(i.string)\n",
    "    elif \"policy\" in i.string.lower():\n",
    "        #print(i.string)\n",
    "        a2.append(i.string)\n",
    "    elif \"exploration\" in i.string.lower():\n",
    "        a3.append(i.string)\n",
    "    elif \"planning\" in i.string.lower():\n",
    "        a4.append(i.string)\n",
    "    elif \"model-based\" in i.string.lower():\n",
    "        a5.append(i.string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = pd.Series(a1, name='reinforcement')\n",
    "s2 = pd.Series(a2, name='policy')\n",
    "s3 = pd.Series(a3, name='exploration')\n",
    "s4 = pd.Series(a4, name='planning')\n",
    "s5 = pd.Series(a5, name='model-based')\n",
    "df = pd.concat([s1,s2,s3,s4,s5], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reinforcement</th>\n",
       "      <th>policy</th>\n",
       "      <th>exploration</th>\n",
       "      <th>planning</th>\n",
       "      <th>model-based</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Importance of Sampling inMeta-Reinforcemen...</td>\n",
       "      <td>Post: Device Placement with Cross-Entropy Mini...</td>\n",
       "      <td>Near Optimal Exploration-Exploitation in Non-C...</td>\n",
       "      <td>Transfer of Deep Reactive Policies for MDP Pla...</td>\n",
       "      <td>Model-based targeted dimensionality reduction ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hybrid Retrieval-Generation Reinforced Agent f...</td>\n",
       "      <td>Evolved Policy Gradients</td>\n",
       "      <td>Playing hard exploration games by watching You...</td>\n",
       "      <td>From Stochastic Planning to Marginal MAP</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DeepExposure: Learning to Expose Photos with A...</td>\n",
       "      <td>Balanced Policy Evaluation and Learning</td>\n",
       "      <td>Context-dependent upper-confidence bounds for ...</td>\n",
       "      <td>Adaptive Path-Integral Autoencoders: Represent...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Learning Temporal Point Processes via Reinforc...</td>\n",
       "      <td>An Off-policy Policy Gradient Theorem Using Em...</td>\n",
       "      <td>Community Exploration: From Offline Optimizati...</td>\n",
       "      <td>Differentiable MPC for End-to-end Planning and...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data-Efficient Hierarchical Reinforcement Lear...</td>\n",
       "      <td>Confounding-Robust Policy Improvement</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Fast deep reinforcement learning using online ...</td>\n",
       "      <td>Recurrent World Models Facilitate Policy Evolu...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Reinforced Continual Learning</td>\n",
       "      <td>Policy Optimization via Importance Sampling</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Inference Aided Reinforcement Learning for Inc...</td>\n",
       "      <td>Breaking the Curse of Horizon: Infinite-Horizo...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Exploration in Structured Reinforcement Learning</td>\n",
       "      <td>Representation Balancing MDPs for Off-policy P...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>A Lyapunov-based Approach to Safe Reinforcemen...</td>\n",
       "      <td>Dual Policy Iteration</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Reinforcement Learning of Theorem Proving</td>\n",
       "      <td>Online Robust Policy Learning in the Presence ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Simple random search of static linear policies...</td>\n",
       "      <td>On Learning Intrinsic Rewards for Policy Gradi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Meta-Gradient Reinforcement Learning</td>\n",
       "      <td>Memory Augmented Policy Optimization for Progr...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Reinforcement Learning for Solving the Vehicle...</td>\n",
       "      <td>Graph Convolutional Policy Network for Goal-Di...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Learn What Not to Learn: Action Elimination wi...</td>\n",
       "      <td>A Deep Bayesian Policy Reuse Approach Against ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>REFUEL: Exploring Sparse Features in Deep Rein...</td>\n",
       "      <td>Actor-Critic Policy Optimization in Partially ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Improving Exploration in Evolution Strategies ...</td>\n",
       "      <td>Single-Agent Policy Tree Search With Guarantees</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Distributed Multitask Reinforcement Learning w...</td>\n",
       "      <td>Policy Regret in Repeated Games</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Constrained Cross-Entropy Method for Safe Rein...</td>\n",
       "      <td>Learning convex bounds for linear quadratic co...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Reinforcement Learning with Multiple Experts: ...</td>\n",
       "      <td>Policy-Conditioned Uncertainty Sets for Robust...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Verifiable Reinforcement Learning via Policy E...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Deep Reinforcement Learning of Marked Temporal...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Evolution-Guided Policy Gradient in Reinforcem...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Meta-Reinforcement Learning of Structured Expl...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Diversity-Driven Exploration Strategy for Deep...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Genetic-Gated Networks for Deep Reinforcement ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Visual Reinforcement Learning with Imagined Goals</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Unsupervised Video Object Segmentation for Dee...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Zero-Shot Transfer with Deictic Object-Oriente...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Total stochastic gradient algorithms and appli...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Fighting Boredom in Recommender Systems with L...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Randomized Prior Functions for Deep Reinforcem...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Scalable Coordinated Exploration in Concurrent...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Multi-Agent Reinforcement Learning via Double ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Negotiable Reinforcement Learning for Pareto O...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Teaching Inverse Reinforcement Learners via Fe...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Hierarchical Reinforcement Learning for Zero-s...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Lifelong Inverse Reinforcement Learning</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Multiple-Step Greedy Policies in Approximate a...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Deep Reinforcement Learning in a Handful of Tr...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Sample-Efficient Reinforcement Learning with S...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        reinforcement  \\\n",
       "0   The Importance of Sampling inMeta-Reinforcemen...   \n",
       "1   Hybrid Retrieval-Generation Reinforced Agent f...   \n",
       "2   DeepExposure: Learning to Expose Photos with A...   \n",
       "3   Learning Temporal Point Processes via Reinforc...   \n",
       "4   Data-Efficient Hierarchical Reinforcement Lear...   \n",
       "5   Fast deep reinforcement learning using online ...   \n",
       "6                       Reinforced Continual Learning   \n",
       "7   Inference Aided Reinforcement Learning for Inc...   \n",
       "8    Exploration in Structured Reinforcement Learning   \n",
       "9   A Lyapunov-based Approach to Safe Reinforcemen...   \n",
       "10          Reinforcement Learning of Theorem Proving   \n",
       "11  Simple random search of static linear policies...   \n",
       "12               Meta-Gradient Reinforcement Learning   \n",
       "13  Reinforcement Learning for Solving the Vehicle...   \n",
       "14  Learn What Not to Learn: Action Elimination wi...   \n",
       "15  REFUEL: Exploring Sparse Features in Deep Rein...   \n",
       "16  Improving Exploration in Evolution Strategies ...   \n",
       "17  Distributed Multitask Reinforcement Learning w...   \n",
       "18  Constrained Cross-Entropy Method for Safe Rein...   \n",
       "19  Reinforcement Learning with Multiple Experts: ...   \n",
       "20  Verifiable Reinforcement Learning via Policy E...   \n",
       "21  Deep Reinforcement Learning of Marked Temporal...   \n",
       "22  Evolution-Guided Policy Gradient in Reinforcem...   \n",
       "23  Meta-Reinforcement Learning of Structured Expl...   \n",
       "24  Diversity-Driven Exploration Strategy for Deep...   \n",
       "25  Genetic-Gated Networks for Deep Reinforcement ...   \n",
       "26  Visual Reinforcement Learning with Imagined Goals   \n",
       "27  Unsupervised Video Object Segmentation for Dee...   \n",
       "28  Zero-Shot Transfer with Deictic Object-Oriente...   \n",
       "29  Total stochastic gradient algorithms and appli...   \n",
       "30  Fighting Boredom in Recommender Systems with L...   \n",
       "31  Randomized Prior Functions for Deep Reinforcem...   \n",
       "32  Scalable Coordinated Exploration in Concurrent...   \n",
       "33  Multi-Agent Reinforcement Learning via Double ...   \n",
       "34  Negotiable Reinforcement Learning for Pareto O...   \n",
       "35  Teaching Inverse Reinforcement Learners via Fe...   \n",
       "36  Hierarchical Reinforcement Learning for Zero-s...   \n",
       "37            Lifelong Inverse Reinforcement Learning   \n",
       "38  Multiple-Step Greedy Policies in Approximate a...   \n",
       "39  Deep Reinforcement Learning in a Handful of Tr...   \n",
       "40  Sample-Efficient Reinforcement Learning with S...   \n",
       "\n",
       "                                               policy  \\\n",
       "0   Post: Device Placement with Cross-Entropy Mini...   \n",
       "1                            Evolved Policy Gradients   \n",
       "2             Balanced Policy Evaluation and Learning   \n",
       "3   An Off-policy Policy Gradient Theorem Using Em...   \n",
       "4               Confounding-Robust Policy Improvement   \n",
       "5   Recurrent World Models Facilitate Policy Evolu...   \n",
       "6         Policy Optimization via Importance Sampling   \n",
       "7   Breaking the Curse of Horizon: Infinite-Horizo...   \n",
       "8   Representation Balancing MDPs for Off-policy P...   \n",
       "9                               Dual Policy Iteration   \n",
       "10  Online Robust Policy Learning in the Presence ...   \n",
       "11  On Learning Intrinsic Rewards for Policy Gradi...   \n",
       "12  Memory Augmented Policy Optimization for Progr...   \n",
       "13  Graph Convolutional Policy Network for Goal-Di...   \n",
       "14  A Deep Bayesian Policy Reuse Approach Against ...   \n",
       "15  Actor-Critic Policy Optimization in Partially ...   \n",
       "16    Single-Agent Policy Tree Search With Guarantees   \n",
       "17                    Policy Regret in Repeated Games   \n",
       "18  Learning convex bounds for linear quadratic co...   \n",
       "19  Policy-Conditioned Uncertainty Sets for Robust...   \n",
       "20                                                NaN   \n",
       "21                                                NaN   \n",
       "22                                                NaN   \n",
       "23                                                NaN   \n",
       "24                                                NaN   \n",
       "25                                                NaN   \n",
       "26                                                NaN   \n",
       "27                                                NaN   \n",
       "28                                                NaN   \n",
       "29                                                NaN   \n",
       "30                                                NaN   \n",
       "31                                                NaN   \n",
       "32                                                NaN   \n",
       "33                                                NaN   \n",
       "34                                                NaN   \n",
       "35                                                NaN   \n",
       "36                                                NaN   \n",
       "37                                                NaN   \n",
       "38                                                NaN   \n",
       "39                                                NaN   \n",
       "40                                                NaN   \n",
       "\n",
       "                                          exploration  \\\n",
       "0   Near Optimal Exploration-Exploitation in Non-C...   \n",
       "1   Playing hard exploration games by watching You...   \n",
       "2   Context-dependent upper-confidence bounds for ...   \n",
       "3   Community Exploration: From Offline Optimizati...   \n",
       "4                                                 NaN   \n",
       "5                                                 NaN   \n",
       "6                                                 NaN   \n",
       "7                                                 NaN   \n",
       "8                                                 NaN   \n",
       "9                                                 NaN   \n",
       "10                                                NaN   \n",
       "11                                                NaN   \n",
       "12                                                NaN   \n",
       "13                                                NaN   \n",
       "14                                                NaN   \n",
       "15                                                NaN   \n",
       "16                                                NaN   \n",
       "17                                                NaN   \n",
       "18                                                NaN   \n",
       "19                                                NaN   \n",
       "20                                                NaN   \n",
       "21                                                NaN   \n",
       "22                                                NaN   \n",
       "23                                                NaN   \n",
       "24                                                NaN   \n",
       "25                                                NaN   \n",
       "26                                                NaN   \n",
       "27                                                NaN   \n",
       "28                                                NaN   \n",
       "29                                                NaN   \n",
       "30                                                NaN   \n",
       "31                                                NaN   \n",
       "32                                                NaN   \n",
       "33                                                NaN   \n",
       "34                                                NaN   \n",
       "35                                                NaN   \n",
       "36                                                NaN   \n",
       "37                                                NaN   \n",
       "38                                                NaN   \n",
       "39                                                NaN   \n",
       "40                                                NaN   \n",
       "\n",
       "                                             planning  \\\n",
       "0   Transfer of Deep Reactive Policies for MDP Pla...   \n",
       "1            From Stochastic Planning to Marginal MAP   \n",
       "2   Adaptive Path-Integral Autoencoders: Represent...   \n",
       "3   Differentiable MPC for End-to-end Planning and...   \n",
       "4                                                 NaN   \n",
       "5                                                 NaN   \n",
       "6                                                 NaN   \n",
       "7                                                 NaN   \n",
       "8                                                 NaN   \n",
       "9                                                 NaN   \n",
       "10                                                NaN   \n",
       "11                                                NaN   \n",
       "12                                                NaN   \n",
       "13                                                NaN   \n",
       "14                                                NaN   \n",
       "15                                                NaN   \n",
       "16                                                NaN   \n",
       "17                                                NaN   \n",
       "18                                                NaN   \n",
       "19                                                NaN   \n",
       "20                                                NaN   \n",
       "21                                                NaN   \n",
       "22                                                NaN   \n",
       "23                                                NaN   \n",
       "24                                                NaN   \n",
       "25                                                NaN   \n",
       "26                                                NaN   \n",
       "27                                                NaN   \n",
       "28                                                NaN   \n",
       "29                                                NaN   \n",
       "30                                                NaN   \n",
       "31                                                NaN   \n",
       "32                                                NaN   \n",
       "33                                                NaN   \n",
       "34                                                NaN   \n",
       "35                                                NaN   \n",
       "36                                                NaN   \n",
       "37                                                NaN   \n",
       "38                                                NaN   \n",
       "39                                                NaN   \n",
       "40                                                NaN   \n",
       "\n",
       "                                          model-based  \n",
       "0   Model-based targeted dimensionality reduction ...  \n",
       "1                                                 NaN  \n",
       "2                                                 NaN  \n",
       "3                                                 NaN  \n",
       "4                                                 NaN  \n",
       "5                                                 NaN  \n",
       "6                                                 NaN  \n",
       "7                                                 NaN  \n",
       "8                                                 NaN  \n",
       "9                                                 NaN  \n",
       "10                                                NaN  \n",
       "11                                                NaN  \n",
       "12                                                NaN  \n",
       "13                                                NaN  \n",
       "14                                                NaN  \n",
       "15                                                NaN  \n",
       "16                                                NaN  \n",
       "17                                                NaN  \n",
       "18                                                NaN  \n",
       "19                                                NaN  \n",
       "20                                                NaN  \n",
       "21                                                NaN  \n",
       "22                                                NaN  \n",
       "23                                                NaN  \n",
       "24                                                NaN  \n",
       "25                                                NaN  \n",
       "26                                                NaN  \n",
       "27                                                NaN  \n",
       "28                                                NaN  \n",
       "29                                                NaN  \n",
       "30                                                NaN  \n",
       "31                                                NaN  \n",
       "32                                                NaN  \n",
       "33                                                NaN  \n",
       "34                                                NaN  \n",
       "35                                                NaN  \n",
       "36                                                NaN  \n",
       "37                                                NaN  \n",
       "38                                                NaN  \n",
       "39                                                NaN  \n",
       "40                                                NaN  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel(\"nips2018_rl.xlsx\", encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
