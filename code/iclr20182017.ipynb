{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen\n",
    "from selenium import webdriver\n",
    "import pandas as pd\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = \"https://openreview.net/group?id=ICLR.cc/2018/Conference#accepted-poster-papers\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(executable_path = \"C://Users//Raychiu//chromedriver_win32//chromedriver.exe\")\n",
    "driver.get(html)\n",
    "sleep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<selenium.webdriver.remote.webelement.WebElement (session=\"ddcb9268a07343a611996170b60c8d37\", element=\"0.6650916250610637-1\")>\n"
     ]
    }
   ],
   "source": [
    "content_element = driver.find_element_by_class_name(\"tab-content\")\n",
    "content_html = content_element.get_attribute(\"innerHTML\")\n",
    "print(content_element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(content_html, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "div_tag_poster = soup.find_all(\"div\", id = \"accepted-poster-papers\")\n",
    "div_tag_oral = soup.find_all(\"div\", id = \"accepted-oral-papers\")\n",
    "div_tag_reject = soup.find_all(\"div\", id = \"rejected-papers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "li_tag_poster = div_tag_poster[0].find_all(\"li\", class_ = \"note\")\n",
    "li_tag_oral = div_tag_oral[0].find_all(\"li\", class_ = \"note\")\n",
    "li_tag_reject = div_tag_reject[0].find_all(\"li\", class_ = \"note\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "a1 = []\n",
    "a2 = []\n",
    "for li in li_tag_poster:\n",
    "    a1.append(li.find(\"h4\").find(\"a\").string.strip())\n",
    "for li in li_tag_oral:\n",
    "    a1.append(li.find(\"h4\").find(\"a\").string.strip())\n",
    "for li in li_tag_reject:\n",
    "    a2.append(li.find(\"h4\").find(\"a\").string.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "337\n",
      "508\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Minimal-Entropy Correlation Alignment for Unsupervised Deep Domain Adaptation',\n",
       " 'Large Scale Optimal Transport and Mapping Estimation',\n",
       " 'TRUNCATED HORIZON POLICY SEARCH: COMBINING REINFORCEMENT LEARNING & IMITATION LEARNING',\n",
       " 'Model-Ensemble Trust-Region Policy Optimization',\n",
       " 'A Neural Representation of Sketch Drawings',\n",
       " 'Deep Learning with Logged Bandit Feedback',\n",
       " 'Learning Latent Permutations with Gumbel-Sinkhorn Networks',\n",
       " 'Learning an Embedding Space for Transferable Robot Skills',\n",
       " 'Unsupervised Learning of Goal Spaces for Intrinsically Motivated Goal Exploration',\n",
       " 'Multi-View Data Generation Without View Supervision',\n",
       " 'Deep Bayesian Bandits Showdown:  An Empirical Comparison of Bayesian Deep Networks for Thompson Sampling',\n",
       " 'Semantic Interpolation in Implicit Models',\n",
       " 'Fidelity-Weighted Learning',\n",
       " 'Latent Space Oddity: on the Curvature of Deep Generative Models',\n",
       " 'Imitation Learning from Visual Data with Multiple Intentions',\n",
       " 'Hyperparameter optimization: a spectral approach',\n",
       " 'Leveraging Grammar and Reinforcement Learning for Neural Program Synthesis',\n",
       " 'Efficient Sparse-Winograd Convolutional Neural Networks',\n",
       " 'Espresso: Efficient Forward Propagation for Binary Deep Neural Networks',\n",
       " 'Auto-Conditioned Recurrent Networks for Extended Complex Human Motion Synthesis',\n",
       " 'Decoupling the Layers in Residual Networks',\n",
       " 'Polar Transformer Networks',\n",
       " 'Enhancing The Reliability of Out-of-distribution Image Detection in Neural Networks',\n",
       " 'Stabilizing Adversarial Nets with Prediction Methods',\n",
       " 'Graph Attention Networks',\n",
       " 'Minimax Curriculum Learning: Machine Teaching with Desirable Difficulties and Scheduled Diversity',\n",
       " 'Generalizing Hamiltonian Monte Carlo with Neural Networks',\n",
       " 'An Online Learning Approach to Generative Adversarial Networks',\n",
       " 'Improving GANs Using Optimal Transport',\n",
       " 'The Kanerva Machine: A Generative Distributed Memory',\n",
       " 'Mixed Precision Training',\n",
       " 'Latent Constraints: Learning to Generate Conditionally from Unconditional Generative Models',\n",
       " 'MaskGAN: Better Text Generation via Filling in the _______',\n",
       " 'Divide and Conquer Networks',\n",
       " 'Meta-Learning and Universality: Deep Representations and Gradient Descent can Approximate any Learning Algorithm',\n",
       " 'Maximum a Posteriori Policy Optimisation',\n",
       " 'META LEARNING SHARED HIERARCHIES',\n",
       " 'Deep Neural Networks as Gaussian Processes',\n",
       " 'Syntax-Directed Variational Autoencoder for Structured Data',\n",
       " 'Neural-Guided Deductive Search for Real-Time Program Synthesis from Examples',\n",
       " 'Evidence Aggregation for Answer Re-Ranking in Open-Domain Question Answering',\n",
       " 'WRPN: Wide Reduced-Precision Networks',\n",
       " 'MGAN: Training Generative Adversarial Nets with Multiple Generators',\n",
       " 'The Reactor: A fast and sample-efficient Actor-Critic agent for  Reinforcement Learning',\n",
       " 'SEARNN: Training RNNs with global-local losses',\n",
       " 'Distributed Distributional Deterministic Policy Gradients',\n",
       " 'Hierarchical Subtask Discovery with Non-Negative Matrix Factorization',\n",
       " 'Parametrized Hierarchical Procedures for Neural Programming',\n",
       " 'Viterbi-based Pruning for Sparse Matrix with Fixed and High Index Compression Ratio',\n",
       " 'cGANs with Projection Discriminator',\n",
       " 'Unsupervised Representation Learning by Predicting Image Rotations',\n",
       " 'Emergent Communication in a Multi-Modal, Multi-Step Referential Game',\n",
       " 'FastGCN: Fast Learning with Graph Convolutional Networks via Importance Sampling',\n",
       " 'Emergent Translation in Multi-Agent Communication',\n",
       " 'An efficient framework for learning sentence representations',\n",
       " 'NerveNet: Learning Structured Policy with Graph Neural Networks',\n",
       " 'Learning Latent Representations in Neural Networks for Clustering through Pseudo Supervision and Graph-based Activity Regularization',\n",
       " 'Adversarial Dropout Regularization',\n",
       " 'Demystifying MMD GANs',\n",
       " 'Smooth Loss Functions for Deep Top-k Classification',\n",
       " 'Deep Learning as a Mixed Convex-Combinatorial Optimization Problem',\n",
       " 'Learning Approximate Inference Networks for Structured Prediction',\n",
       " 'LEARNING TO SHARE: SIMULTANEOUS PARAMETER TYING AND SPARSIFICATION IN DEEP LEARNING',\n",
       " 'Model compression via distillation and quantization',\n",
       " 'Variational Message Passing with Structured Inference Networks',\n",
       " 'Action-dependent Control Variates for Policy Optimization via Stein Identity',\n",
       " 'Variational image compression with a scale hyperprior',\n",
       " 'Variational Inference of Disentangled Latent Concepts from Unlabeled Observations',\n",
       " 'Flipout: Efficient Pseudo-Independent Weight Perturbations on Mini-Batches',\n",
       " 'Kernel Implicit Variational Inference',\n",
       " 'A Scalable Laplace Approximation for Neural Networks',\n",
       " 'The High-Dimensional Geometry of Binary Neural Networks',\n",
       " 'Apprentice: Using Knowledge Distillation Techniques To Improve Low-Precision Network Accuracy',\n",
       " 'Distributed Prioritized Experience Replay',\n",
       " 'Learning from Between-class Examples for Deep Sound Recognition',\n",
       " 'Training Confidence-calibrated Classifiers for Detecting Out-of-Distribution Samples',\n",
       " 'VoiceLoop: Voice Fitting and Synthesis via a Phonological Loop',\n",
       " 'Large scale distributed neural network training through online distillation',\n",
       " 'Learning Differentially Private Recurrent Language Models',\n",
       " 'Mastering the Dungeon: Grounded Language Learning by Mechanical Turker Descent',\n",
       " 'Generating Wikipedia by Summarizing Long Sequences',\n",
       " 'Unsupervised Machine Translation Using Monolingual Corpora Only',\n",
       " 'A Deep Reinforced Model for Abstractive Summarization',\n",
       " 'Compressing Word Embeddings via Deep Compositional Code Learning',\n",
       " 'Deep Gradient Compression: Reducing the Communication Bandwidth for Distributed Training',\n",
       " 'QANet: Combining Local Convolution with Global Self-Attention for Reading Comprehension',\n",
       " 'Unsupervised Neural Machine Translation',\n",
       " 'Learning One-hidden-layer Neural Networks with Landscape Design',\n",
       " 'Critical Points of Linear Neural Networks: Analytical Forms and Landscape Properties',\n",
       " 'Learning Parametric Closed-Loop Policies for Markov Potential Games',\n",
       " 'The power of deeper networks for expressing natural functions',\n",
       " 'Empirical Risk Landscape Analysis for Understanding Deep Neural Networks',\n",
       " 'On the Discrimination-Generalization Tradeoff in GANs',\n",
       " 'Decision-Based Adversarial Attacks: Reliable Attacks Against Black-Box Machine Learning Models',\n",
       " 'Unbiased Online Recurrent Optimization',\n",
       " 'Measuring the Intrinsic Dimension of Objective Landscapes',\n",
       " 'Memorization Precedes Generation: Learning Unsupervised GANs with Memory Networks',\n",
       " 'Stochastic Activation Pruning for Robust Adversarial Defense',\n",
       " 'Sparse Persistent RNNs: Squeezing Large Recurrent Networks On-Chip',\n",
       " 'GANITE: Estimation of Individualized Treatment Effects using Generative Adversarial Nets',\n",
       " 'Thermometer Encoding: One Hot Way To Resist Adversarial Examples',\n",
       " 'Trust-PCL: An Off-Policy Trust Region Method for Continuous Control',\n",
       " 'Stochastic Variational Video Prediction',\n",
       " 'Towards Image Understanding from Deep Compression Without Decoding',\n",
       " 'Automatically Inferring Data Quality for Spatiotemporal Forecasting',\n",
       " 'Towards better understanding of gradient-based attribution methods for Deep Neural Networks',\n",
       " 'Countering Adversarial Images using Input Transformations',\n",
       " 'Skip RNN: Learning to Skip State Updates in Recurrent Neural Networks',\n",
       " 'Modular Continual Learning in a Unified Visual Environment',\n",
       " 'Twin Networks: Matching the Future for Sequence Generation',\n",
       " 'Interpretable Counting for Visual Question Answering',\n",
       " 'Interactive Grounded Language Acquisition and Generalization in a 2D World',\n",
       " 'Emergent Complexity via Multi-Agent Competition',\n",
       " 'Universal Agent for Disentangling Environments and Tasks',\n",
       " 'Residual Connections Encourage Iterative Inference',\n",
       " 'Emergent Communication through Negotiation',\n",
       " 'Semi-parametric topological memory for navigation',\n",
       " 'Learning to Count Objects in Natural Images for Visual Question Answering',\n",
       " 'i-RevNet: Deep Invertible Networks',\n",
       " 'Evaluating the Robustness of Neural Networks: An Extreme Value Theory Approach',\n",
       " 'HexaConv',\n",
       " 'Towards Deep Learning Models Resistant to Adversarial Attacks',\n",
       " 'Deep Learning for Physical Processes: Incorporating Prior Scientific Knowledge',\n",
       " 'Communication Algorithms via Deep Learning',\n",
       " 'Simulating Action Dynamics with Neural Process Networks',\n",
       " 'Unsupervised Cipher Cracking Using Discrete GANs',\n",
       " 'Neural Speed Reading via Skim-RNN',\n",
       " 'Multi-level Residual Networks from Dynamical Systems View',\n",
       " 'Towards Neural Phrase-based Machine Translation',\n",
       " 'On the State of the Art of Evaluation in Neural Language Models',\n",
       " 'Memory-based Parameter Adaptation',\n",
       " 'Initialization matters: Orthogonal Predictive State Recurrent Neural Networks',\n",
       " 'PixelDefend: Leveraging Generative Models to Understand and Defend against Adversarial Examples',\n",
       " 'Certified Defenses against Adversarial Examples',\n",
       " 'Defense-GAN: Protecting Classifiers Against Adversarial Attacks Using Generative Models',\n",
       " 'Ensemble Adversarial Training: Attacks and Defenses',\n",
       " 'Fraternal Dropout',\n",
       " 'Can recurrent neural networks warp time?',\n",
       " 'Parallelizing Linear Recurrent Neural Nets Over Sequence Length',\n",
       " 'Attacking Binarized Neural Networks',\n",
       " 'Depthwise Separable Convolutions for Neural Machine Translation',\n",
       " 'Noisy Networks For Exploration',\n",
       " 'A Hierarchical Model for Device Placement',\n",
       " 'Deep Autoencoding Gaussian Mixture Model for Unsupervised Anomaly Detection',\n",
       " 'Learning Discrete Weights Using the Local Reparameterization Trick',\n",
       " 'Deep Rewiring: Training very sparse deep networks',\n",
       " 'Quantitatively Evaluating GANs With Divergences Proposed for Training',\n",
       " 'Improving GAN Training via Binarized Representation Entropy (BRE) Regularization',\n",
       " 'Generative networks as inverse problems with Scattering transforms',\n",
       " 'Critical Percolation as a Framework to Analyze the Training of Deep Networks',\n",
       " 'On the Expressive Power of Overlapping Architectures of Deep Learning',\n",
       " 'Rethinking the Smaller-Norm-Less-Informative Assumption in Channel Pruning of Convolution Layers',\n",
       " 'Diffusion Convolutional Recurrent Neural Network: Data-Driven Traffic Forecasting',\n",
       " 'Simulated+Unsupervised Learning With Adaptive Data Generation and Bidirectional Mappings',\n",
       " 'Relational Neural Expectation Maximization: Unsupervised Discovery of Objects and their Interactions',\n",
       " 'Generative Models of Visually Grounded Imagination',\n",
       " 'Few-shot Autoregressive Density Estimation: Towards Learning to Learn Distributions',\n",
       " 'Compositional Obverter Communication Learning from Raw Visual Input',\n",
       " 'SCAN: Learning Hierarchical Compositional Visual Concepts',\n",
       " 'Hierarchical Density Order Embeddings',\n",
       " 'Identifying Analogies Across Domains',\n",
       " 'Emergence of grid-like representations by training recurrent neural networks to perform spatial localization',\n",
       " 'Learning a neural response metric for retinal prosthesis',\n",
       " 'Few-Shot Learning with Graph Neural Networks',\n",
       " 'Semantically Decomposing the Latent Spaces of Generative Adversarial Networks',\n",
       " 'A Framework for the Quantitative Evaluation of Disentangled Representations',\n",
       " 'Meta-Learning for Semi-Supervised Few-Shot Classification',\n",
       " 'A DIRT-T Approach to Unsupervised Domain Adaptation',\n",
       " 'Generalizing Across Domains via Cross-Gradient Training',\n",
       " 'Learning to cluster in order to transfer across domains and tasks',\n",
       " 'Deep Complex Networks',\n",
       " 'Skip Connections Eliminate Singularities',\n",
       " 'Bi-Directional Block Self-Attention for Fast and Memory-Efficient Sequence Modeling',\n",
       " 'Routing Networks: Adaptive Selection of Non-Linear Functions for Multi-Task Learning',\n",
       " 'Wavelet Pooling for Convolutional Neural Networks',\n",
       " 'FearNet: Brain-Inspired Model for Incremental Learning',\n",
       " 'Do GANs learn the distribution? Some Theory and Empirics',\n",
       " 'Towards Reverse-Engineering Black-Box Neural Networks',\n",
       " 'Understanding Deep Neural Networks with Rectified Linear Units',\n",
       " 'Training wide residual networks for deployment using a single bit for each weight',\n",
       " 'Learn to Pay Attention',\n",
       " 'Monotonic Chunkwise Attention',\n",
       " 'Recasting Gradient-Based Meta-Learning as Hierarchical Bayes',\n",
       " \"Don't Decay the Learning Rate, Increase the Batch Size\",\n",
       " 'Kronecker-factored Curvature Approximations for Recurrent Neural Networks',\n",
       " 'Proximal Backpropagation',\n",
       " 'Neumann Optimizer: A Practical Optimization Algorithm for Deep Neural Networks',\n",
       " 'SGD Learns Over-parameterized Networks that Provably Generalize on Linearly Separable Data',\n",
       " 'A PAC-Bayesian Approach to Spectrally-Normalized Margin Bounds for Neural Networks',\n",
       " 'On the importance of single directions for generalization',\n",
       " 'The Implicit Bias of Gradient Descent on Separable Data',\n",
       " 'Many Paths to Equilibrium: GANs Do Not Need to Decrease a Divergence At Every Step',\n",
       " 'Adaptive Dropout with Rademacher Complexity Regularization',\n",
       " 'A Bayesian Perspective on Generalization and Stochastic Gradient Descent',\n",
       " 'Implicit Causal Models for Genome-wide Association Studies',\n",
       " 'Sensitivity and Generalization in Neural Networks: an Empirical Study',\n",
       " 'Regularizing and Optimizing LSTM Language Models',\n",
       " 'DCN+: Mixed Objective And Deep Residual Coattention for Question Answering',\n",
       " 'Word translation without parallel data',\n",
       " 'All-but-the-Top: Simple and Effective Postprocessing for Word Representations',\n",
       " 'Learning General Purpose Distributed Sentence Representations via Large Scale Multi-task Learning',\n",
       " 'Natural Language Inference over Interaction Space',\n",
       " 'Multi-Task Learning for Document Ranking and Query Suggestion',\n",
       " 'Distributed Fine-tuning of Language Models on Private Data',\n",
       " 'Intrinsic Motivation and Automatic Curricula via Asymmetric Self-Play',\n",
       " 'Reinforcement Learning Algorithm Selection',\n",
       " 'Leave no Trace: Learning to Reset for Safe and Autonomous Reinforcement Learning',\n",
       " 'Consequentialist conditional cooperation in social dilemmas with imperfect information',\n",
       " 'Can Neural Networks Understand Logical Entailment?',\n",
       " 'Cascade Adversarial Machine Learning Regularized with a Unified Embedding',\n",
       " 'Mitigating Adversarial Effects Through Randomization',\n",
       " 'Decision Boundary Analysis of Adversarial Examples',\n",
       " 'Matrix capsules with EM routing',\n",
       " 'CausalGAN: Learning Causal Implicit Generative Models with Adversarial Training',\n",
       " 'Learning Wasserstein Embeddings',\n",
       " 'TRAINING GENERATIVE ADVERSARIAL NETWORKS VIA PRIMAL-DUAL SUBGRADIENT METHODS: A LAGRANGIAN PERSPECTIVE ON GAN',\n",
       " 'Activation Maximization Generative Adversarial Nets',\n",
       " 'Coulomb GANs: Provably Optimal Nash Equilibria via Potential Fields',\n",
       " 'Improving the Improved Training of Wasserstein GANs: A Consistency Term and Its Dual Effect',\n",
       " 'FusionNet: Fusing via Fully-aware Attention with Application to Machine Comprehension',\n",
       " 'Neural Language Modeling by Jointly Learning Syntax and Lexicon',\n",
       " 'Learning Intrinsic Sparse Structures within Long Short-Term Memory',\n",
       " 'Deep Active Learning for Named Entity Recognition',\n",
       " 'Go for a Walk and Arrive at the Answer: Reasoning Over Paths in Knowledge Bases using Reinforcement Learning',\n",
       " 'No Title',\n",
       " 'Lifelong Learning with Dynamically Expandable Networks',\n",
       " 'The Role of Minimal Complexity Functions in Unsupervised Learning of Semantic Mappings',\n",
       " 'Dynamic Neural Program Embeddings for Program Repair',\n",
       " 'Compositional Attention Networks for Machine Reasoning',\n",
       " 'Beyond Shared Hierarchies: Deep Multitask Learning through Soft Layer Ordering',\n",
       " 'Hierarchical Representations for Efficient Architecture Search',\n",
       " 'Reinforcement Learning on Web Interfaces using Workflow-Guided Exploration',\n",
       " 'Combining Symbolic Expressions and Black-box Function Evaluations in Neural Programs',\n",
       " 'Scalable Private Learning with PATE',\n",
       " 'Active Learning for Convolutional Neural Networks: A Core-Set Approach',\n",
       " 'Loss-aware Weight Quantization of Deep Networks',\n",
       " 'Global Optimality Conditions for Deep Neural Networks',\n",
       " 'SpectralNet: Spectral Clustering using Deep Neural Networks',\n",
       " 'Not-So-Random Features',\n",
       " 'Learning how to explain neural networks: PatternNet and PatternAttribution',\n",
       " 'Detecting Statistical Interactions from Neural Network Weights',\n",
       " 'Deep Gaussian Embedding of Graphs: Unsupervised Inductive Learning via Ranking',\n",
       " 'Generating Natural Adversarial Examples',\n",
       " 'Spatially Transformed Adversarial Examples',\n",
       " 'Predicting Floor-Level for 911 Calls with Neural Networks and Smartphone Sensor Data',\n",
       " 'Understanding image motion with group representations',\n",
       " 'Learning Awareness Models',\n",
       " 'Backpropagation through the Void: Optimizing control variates for black-box gradient estimation',\n",
       " 'On Unifying Deep Generative Models',\n",
       " 'Debiasing Evidence Approximations: On Importance-weighted Autoencoders and Jackknife Variational Inference',\n",
       " 'Learning a Generative Model for Validity in Complex Discrete Structures',\n",
       " 'Boundary Seeking GANs',\n",
       " 'Learning Sparse Latent Representations with the Deep Copula Information Bottleneck',\n",
       " 'WHAI: Weibull Hybrid Autoencoding Inference for Deep Topic Modeling',\n",
       " 'Understanding Short-Horizon Bias in Stochastic Meta-Optimization',\n",
       " 'Self-ensembling for visual domain adaptation',\n",
       " 'Gradient Estimators for Implicit Models',\n",
       " 'Learning to Multi-Task by Active Sampling',\n",
       " 'Learning Robust Rewards with Adverserial Inverse Reinforcement Learning',\n",
       " 'A Simple Neural Attentive Meta-Learner',\n",
       " 'Deep Learning and Quantum Entanglement: Fundamental Connections with Implications to Network Design',\n",
       " 'Towards Synthesizing Complex Programs From Input-Output Examples',\n",
       " 'Expressive power of recurrent neural networks',\n",
       " 'Improving the Universality and Learnability of Neural Programmer-Interpreters with Combinator Abstraction',\n",
       " 'An image representation based convolutional network for DNA classification',\n",
       " 'SMASH: One-Shot Model Architecture Search through HyperNetworks',\n",
       " 'Parameter Space Noise for Exploration',\n",
       " 'Synthesizing realistic neural population activity patterns using Generative Adversarial Networks',\n",
       " 'Auto-Encoding Sequential Monte Carlo',\n",
       " 'Learning to Teach',\n",
       " 'PixelNN: Example-based Image Synthesis',\n",
       " 'Non-Autoregressive Neural Machine Translation',\n",
       " 'Deep Voice 3: Scaling Text-to-Speech with Convolutional Sequence Learning',\n",
       " 'mixup: Beyond Empirical Risk Minimization',\n",
       " 'TD or not TD: Analyzing the Role of Temporal Differencing in Deep Reinforcement Learning',\n",
       " 'DORA The Explorer: Directed Outreaching Reinforcement Action-Selection',\n",
       " 'Temporal Difference Models: Model-Free Deep RL for Model-Based Control',\n",
       " 'TreeQN and ATreeC: Differentiable Tree-Structured Models for Deep Reinforcement Learning',\n",
       " 'Alternating Multi-bit Quantization for Recurrent Neural Networks',\n",
       " 'Residual Loss Prediction: Reinforcement Learning With No Incremental Feedback',\n",
       " 'Adaptive Quantization of Neural Networks',\n",
       " 'Boosting the Actor with Dual Critic',\n",
       " 'Guide Actor-Critic for Continuous Control',\n",
       " 'Policy Optimization by Genetic Distillation',\n",
       " 'When is a Convolutional Filter Easy to Learn?',\n",
       " 'Online Learning Rate Adaptation with Hypergradient Descent',\n",
       " 'Stochastic gradient descent performs variational inference, converges to limit cycles for deep networks',\n",
       " 'Robustness of Classifiers to Universal Perturbations: A Geometric Perspective',\n",
       " 'On the regularization of Wasserstein GANs',\n",
       " 'Eigenoption Discovery through the Deep Successor Representation',\n",
       " 'Neural Map: Structured Memory for Deep Reinforcement Learning',\n",
       " 'Active Neural Localization',\n",
       " 'Overcoming Catastrophic Interference using Conceptor-Aided Backpropagation',\n",
       " 'Memory Augmented Control Networks',\n",
       " 'Progressive Reinforcement Learning with Distillation for Multi-Skilled Motion Control',\n",
       " 'N2N learning: Network to Network Compression via Policy Gradient Reinforcement Learning',\n",
       " 'Hierarchical and Interpretable Skill Acquisition in Multi-task Reinforcement Learning',\n",
       " 'Divide-and-Conquer Reinforcement Learning',\n",
       " 'A Compressed Sensing View of Unsupervised Text Embeddings, Bag-of-n-Grams, and LSTMs',\n",
       " 'A New Method of Region Embedding for Text Classification',\n",
       " 'Fix your classifier: the marginal value of training the last weight layer',\n",
       " 'Multi-Mention Learning for Reading Comprehension with Neural Cascades',\n",
       " 'Deep Sensing: Active Sensing using Multi-directional Recurrent Neural Networks',\n",
       " 'Temporally Efficient Deep Learning with Spikes',\n",
       " 'Variational Network Quantization',\n",
       " 'Training GANs with Optimism',\n",
       " 'Sobolev GAN',\n",
       " 'Learning From Noisy Singly-labeled Data',\n",
       " 'Learning Sparse Neural Networks through L_0 Regularization',\n",
       " 'Variational Continual Learning',\n",
       " 'Gaussian Process Behaviour in Wide Deep Neural Networks',\n",
       " 'Mixed Precision Training of Convolutional Neural Networks using Integer Operations',\n",
       " 'Memory Architectures in Recurrent Neural Network Language Models',\n",
       " 'On the Information Bottleneck Theory of Deep Learning',\n",
       " 'On the Convergence of Adam and Beyond',\n",
       " 'Synthetic and Natural Noise Both Break Neural Machine Translation',\n",
       " 'Multi-Scale Dense Networks for Resource Efficient Image Classification',\n",
       " 'Training and Inference with Integers in Deep Neural Networks',\n",
       " 'Emergence of Linguistic Communication from  Referential Games with Symbolic and Pixel Input',\n",
       " 'Spherical CNNs',\n",
       " 'Ask the Right Questions: Active Question Reformulation with Reinforcement Learning',\n",
       " 'On the insufficiency of existing momentum schemes for Stochastic Optimization',\n",
       " 'Certifying Some Distributional Robustness with Principled Adversarial Training',\n",
       " 'Learning Deep Mean Field Games for Modeling Large Population Behavior',\n",
       " 'Wasserstein Auto-Encoders',\n",
       " 'Spectral Normalization for Generative Adversarial Networks',\n",
       " 'Learning to Represent Programs with Graphs',\n",
       " 'Characterizing Adversarial Subspaces Using Local Intrinsic Dimensionality',\n",
       " 'Breaking the Softmax Bottleneck: A High-Rank RNN Language Model',\n",
       " 'Continuous Adaptation via Meta-Learning in Nonstationary and Competitive Environments',\n",
       " 'Boosting Dilated Convolutional Networks with Mixed Tensor Decompositions',\n",
       " 'Neural Sketch Learning for Conditional Program Generation',\n",
       " 'Progressive Growing of GANs for Improved Quality, Stability, and Variation',\n",
       " 'Variance Reduction for Policy Gradient with Action-Dependent Factorized Baselines',\n",
       " 'Zero-Shot Visual Imitation',\n",
       " 'Beyond Word Importance:  Contextual Decomposition to Extract Interactions from LSTMs',\n",
       " 'AmbientGAN: Generative models from lossy measurements']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(a1))\n",
    "print(len(a2))\n",
    "a1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = \"https://openreview.net/group?id=ICLR.cc/2017/conference\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(executable_path = \"C://Users//Raychiu//chromedriver_win32//chromedriver.exe\")\n",
    "driver.get(html)\n",
    "sleep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_element = driver.find_element_by_id(\"notes\")\n",
    "content_html = content_element.get_attribute(\"innerHTML\")\n",
    "#print(content_html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(content_html, \"html.parser\")\n",
    "#print(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "div_tag_poster = soup.find_all(\"div\")\n",
    "#print(div_tag_poster)\n",
    "def check_paper(div_tag):\n",
    "    global i, conti\n",
    "    \n",
    "    if div_tag.find(\"h2\") == None:\n",
    "        conti = True\n",
    "        #print(\"bad\")\n",
    "        return 0\n",
    "    \n",
    "    if div_tag.find(\"h2\").string == 'Paper decision: Accept (Oral)':\n",
    "        i+=1\n",
    "        conti = True\n",
    "    elif div_tag.find(\"h2\").string == 'Paper decision: Accept (Poster)':\n",
    "        i+=1\n",
    "        conti = True\n",
    "    elif div_tag.find(\"h2\").string == 'Paper decision: Invite to Workshop Track':\n",
    "        i+=1\n",
    "        conti = True\n",
    "    elif div_tag.find(\"h2\").string == 'Paper decision: Reject':\n",
    "        i+=1\n",
    "        conti = True\n",
    "\n",
    "i=0\n",
    "\n",
    "for div in div_tag_poster:\n",
    "    conti = False\n",
    "\n",
    "    check_paper(div)\n",
    "\n",
    "    if conti: \n",
    "        continue\n",
    "        \n",
    "    if i <= 3:\n",
    "        if a1[-1] != div.find(\"h2\").find(\"a\").string.strip():\n",
    "            a1.append(div.find(\"h2\").find(\"a\").string.strip())\n",
    "            \n",
    "    if i == 4:\n",
    "        if a2[-1] != div.find(\"h2\").find(\"a\").string.strip():\n",
    "            a2.append(div.find(\"h2\").find(\"a\").string.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "582\n",
      "753\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Minimal-Entropy Correlation Alignment for Unsupervised Deep Domain Adaptation',\n",
       " 'Large Scale Optimal Transport and Mapping Estimation',\n",
       " 'TRUNCATED HORIZON POLICY SEARCH: COMBINING REINFORCEMENT LEARNING & IMITATION LEARNING',\n",
       " 'Model-Ensemble Trust-Region Policy Optimization',\n",
       " 'A Neural Representation of Sketch Drawings',\n",
       " 'Deep Learning with Logged Bandit Feedback',\n",
       " 'Learning Latent Permutations with Gumbel-Sinkhorn Networks',\n",
       " 'Learning an Embedding Space for Transferable Robot Skills',\n",
       " 'Unsupervised Learning of Goal Spaces for Intrinsically Motivated Goal Exploration',\n",
       " 'Multi-View Data Generation Without View Supervision',\n",
       " 'Deep Bayesian Bandits Showdown:  An Empirical Comparison of Bayesian Deep Networks for Thompson Sampling',\n",
       " 'Semantic Interpolation in Implicit Models',\n",
       " 'Fidelity-Weighted Learning',\n",
       " 'Latent Space Oddity: on the Curvature of Deep Generative Models',\n",
       " 'Imitation Learning from Visual Data with Multiple Intentions',\n",
       " 'Hyperparameter optimization: a spectral approach',\n",
       " 'Leveraging Grammar and Reinforcement Learning for Neural Program Synthesis',\n",
       " 'Efficient Sparse-Winograd Convolutional Neural Networks',\n",
       " 'Espresso: Efficient Forward Propagation for Binary Deep Neural Networks',\n",
       " 'Auto-Conditioned Recurrent Networks for Extended Complex Human Motion Synthesis',\n",
       " 'Decoupling the Layers in Residual Networks',\n",
       " 'Polar Transformer Networks',\n",
       " 'Enhancing The Reliability of Out-of-distribution Image Detection in Neural Networks',\n",
       " 'Stabilizing Adversarial Nets with Prediction Methods',\n",
       " 'Graph Attention Networks',\n",
       " 'Minimax Curriculum Learning: Machine Teaching with Desirable Difficulties and Scheduled Diversity',\n",
       " 'Generalizing Hamiltonian Monte Carlo with Neural Networks',\n",
       " 'An Online Learning Approach to Generative Adversarial Networks',\n",
       " 'Improving GANs Using Optimal Transport',\n",
       " 'The Kanerva Machine: A Generative Distributed Memory',\n",
       " 'Mixed Precision Training',\n",
       " 'Latent Constraints: Learning to Generate Conditionally from Unconditional Generative Models',\n",
       " 'MaskGAN: Better Text Generation via Filling in the _______',\n",
       " 'Divide and Conquer Networks',\n",
       " 'Meta-Learning and Universality: Deep Representations and Gradient Descent can Approximate any Learning Algorithm',\n",
       " 'Maximum a Posteriori Policy Optimisation',\n",
       " 'META LEARNING SHARED HIERARCHIES',\n",
       " 'Deep Neural Networks as Gaussian Processes',\n",
       " 'Syntax-Directed Variational Autoencoder for Structured Data',\n",
       " 'Neural-Guided Deductive Search for Real-Time Program Synthesis from Examples',\n",
       " 'Evidence Aggregation for Answer Re-Ranking in Open-Domain Question Answering',\n",
       " 'WRPN: Wide Reduced-Precision Networks',\n",
       " 'MGAN: Training Generative Adversarial Nets with Multiple Generators',\n",
       " 'The Reactor: A fast and sample-efficient Actor-Critic agent for  Reinforcement Learning',\n",
       " 'SEARNN: Training RNNs with global-local losses',\n",
       " 'Distributed Distributional Deterministic Policy Gradients',\n",
       " 'Hierarchical Subtask Discovery with Non-Negative Matrix Factorization',\n",
       " 'Parametrized Hierarchical Procedures for Neural Programming',\n",
       " 'Viterbi-based Pruning for Sparse Matrix with Fixed and High Index Compression Ratio',\n",
       " 'cGANs with Projection Discriminator',\n",
       " 'Unsupervised Representation Learning by Predicting Image Rotations',\n",
       " 'Emergent Communication in a Multi-Modal, Multi-Step Referential Game',\n",
       " 'FastGCN: Fast Learning with Graph Convolutional Networks via Importance Sampling',\n",
       " 'Emergent Translation in Multi-Agent Communication',\n",
       " 'An efficient framework for learning sentence representations',\n",
       " 'NerveNet: Learning Structured Policy with Graph Neural Networks',\n",
       " 'Learning Latent Representations in Neural Networks for Clustering through Pseudo Supervision and Graph-based Activity Regularization',\n",
       " 'Adversarial Dropout Regularization',\n",
       " 'Demystifying MMD GANs',\n",
       " 'Smooth Loss Functions for Deep Top-k Classification',\n",
       " 'Deep Learning as a Mixed Convex-Combinatorial Optimization Problem',\n",
       " 'Learning Approximate Inference Networks for Structured Prediction',\n",
       " 'LEARNING TO SHARE: SIMULTANEOUS PARAMETER TYING AND SPARSIFICATION IN DEEP LEARNING',\n",
       " 'Model compression via distillation and quantization',\n",
       " 'Variational Message Passing with Structured Inference Networks',\n",
       " 'Action-dependent Control Variates for Policy Optimization via Stein Identity',\n",
       " 'Variational image compression with a scale hyperprior',\n",
       " 'Variational Inference of Disentangled Latent Concepts from Unlabeled Observations',\n",
       " 'Flipout: Efficient Pseudo-Independent Weight Perturbations on Mini-Batches',\n",
       " 'Kernel Implicit Variational Inference',\n",
       " 'A Scalable Laplace Approximation for Neural Networks',\n",
       " 'The High-Dimensional Geometry of Binary Neural Networks',\n",
       " 'Apprentice: Using Knowledge Distillation Techniques To Improve Low-Precision Network Accuracy',\n",
       " 'Distributed Prioritized Experience Replay',\n",
       " 'Learning from Between-class Examples for Deep Sound Recognition',\n",
       " 'Training Confidence-calibrated Classifiers for Detecting Out-of-Distribution Samples',\n",
       " 'VoiceLoop: Voice Fitting and Synthesis via a Phonological Loop',\n",
       " 'Large scale distributed neural network training through online distillation',\n",
       " 'Learning Differentially Private Recurrent Language Models',\n",
       " 'Mastering the Dungeon: Grounded Language Learning by Mechanical Turker Descent',\n",
       " 'Generating Wikipedia by Summarizing Long Sequences',\n",
       " 'Unsupervised Machine Translation Using Monolingual Corpora Only',\n",
       " 'A Deep Reinforced Model for Abstractive Summarization',\n",
       " 'Compressing Word Embeddings via Deep Compositional Code Learning',\n",
       " 'Deep Gradient Compression: Reducing the Communication Bandwidth for Distributed Training',\n",
       " 'QANet: Combining Local Convolution with Global Self-Attention for Reading Comprehension',\n",
       " 'Unsupervised Neural Machine Translation',\n",
       " 'Learning One-hidden-layer Neural Networks with Landscape Design',\n",
       " 'Critical Points of Linear Neural Networks: Analytical Forms and Landscape Properties',\n",
       " 'Learning Parametric Closed-Loop Policies for Markov Potential Games',\n",
       " 'The power of deeper networks for expressing natural functions',\n",
       " 'Empirical Risk Landscape Analysis for Understanding Deep Neural Networks',\n",
       " 'On the Discrimination-Generalization Tradeoff in GANs',\n",
       " 'Decision-Based Adversarial Attacks: Reliable Attacks Against Black-Box Machine Learning Models',\n",
       " 'Unbiased Online Recurrent Optimization',\n",
       " 'Measuring the Intrinsic Dimension of Objective Landscapes',\n",
       " 'Memorization Precedes Generation: Learning Unsupervised GANs with Memory Networks',\n",
       " 'Stochastic Activation Pruning for Robust Adversarial Defense',\n",
       " 'Sparse Persistent RNNs: Squeezing Large Recurrent Networks On-Chip',\n",
       " 'GANITE: Estimation of Individualized Treatment Effects using Generative Adversarial Nets',\n",
       " 'Thermometer Encoding: One Hot Way To Resist Adversarial Examples',\n",
       " 'Trust-PCL: An Off-Policy Trust Region Method for Continuous Control',\n",
       " 'Stochastic Variational Video Prediction',\n",
       " 'Towards Image Understanding from Deep Compression Without Decoding',\n",
       " 'Automatically Inferring Data Quality for Spatiotemporal Forecasting',\n",
       " 'Towards better understanding of gradient-based attribution methods for Deep Neural Networks',\n",
       " 'Countering Adversarial Images using Input Transformations',\n",
       " 'Skip RNN: Learning to Skip State Updates in Recurrent Neural Networks',\n",
       " 'Modular Continual Learning in a Unified Visual Environment',\n",
       " 'Twin Networks: Matching the Future for Sequence Generation',\n",
       " 'Interpretable Counting for Visual Question Answering',\n",
       " 'Interactive Grounded Language Acquisition and Generalization in a 2D World',\n",
       " 'Emergent Complexity via Multi-Agent Competition',\n",
       " 'Universal Agent for Disentangling Environments and Tasks',\n",
       " 'Residual Connections Encourage Iterative Inference',\n",
       " 'Emergent Communication through Negotiation',\n",
       " 'Semi-parametric topological memory for navigation',\n",
       " 'Learning to Count Objects in Natural Images for Visual Question Answering',\n",
       " 'i-RevNet: Deep Invertible Networks',\n",
       " 'Evaluating the Robustness of Neural Networks: An Extreme Value Theory Approach',\n",
       " 'HexaConv',\n",
       " 'Towards Deep Learning Models Resistant to Adversarial Attacks',\n",
       " 'Deep Learning for Physical Processes: Incorporating Prior Scientific Knowledge',\n",
       " 'Communication Algorithms via Deep Learning',\n",
       " 'Simulating Action Dynamics with Neural Process Networks',\n",
       " 'Unsupervised Cipher Cracking Using Discrete GANs',\n",
       " 'Neural Speed Reading via Skim-RNN',\n",
       " 'Multi-level Residual Networks from Dynamical Systems View',\n",
       " 'Towards Neural Phrase-based Machine Translation',\n",
       " 'On the State of the Art of Evaluation in Neural Language Models',\n",
       " 'Memory-based Parameter Adaptation',\n",
       " 'Initialization matters: Orthogonal Predictive State Recurrent Neural Networks',\n",
       " 'PixelDefend: Leveraging Generative Models to Understand and Defend against Adversarial Examples',\n",
       " 'Certified Defenses against Adversarial Examples',\n",
       " 'Defense-GAN: Protecting Classifiers Against Adversarial Attacks Using Generative Models',\n",
       " 'Ensemble Adversarial Training: Attacks and Defenses',\n",
       " 'Fraternal Dropout',\n",
       " 'Can recurrent neural networks warp time?',\n",
       " 'Parallelizing Linear Recurrent Neural Nets Over Sequence Length',\n",
       " 'Attacking Binarized Neural Networks',\n",
       " 'Depthwise Separable Convolutions for Neural Machine Translation',\n",
       " 'Noisy Networks For Exploration',\n",
       " 'A Hierarchical Model for Device Placement',\n",
       " 'Deep Autoencoding Gaussian Mixture Model for Unsupervised Anomaly Detection',\n",
       " 'Learning Discrete Weights Using the Local Reparameterization Trick',\n",
       " 'Deep Rewiring: Training very sparse deep networks',\n",
       " 'Quantitatively Evaluating GANs With Divergences Proposed for Training',\n",
       " 'Improving GAN Training via Binarized Representation Entropy (BRE) Regularization',\n",
       " 'Generative networks as inverse problems with Scattering transforms',\n",
       " 'Critical Percolation as a Framework to Analyze the Training of Deep Networks',\n",
       " 'On the Expressive Power of Overlapping Architectures of Deep Learning',\n",
       " 'Rethinking the Smaller-Norm-Less-Informative Assumption in Channel Pruning of Convolution Layers',\n",
       " 'Diffusion Convolutional Recurrent Neural Network: Data-Driven Traffic Forecasting',\n",
       " 'Simulated+Unsupervised Learning With Adaptive Data Generation and Bidirectional Mappings',\n",
       " 'Relational Neural Expectation Maximization: Unsupervised Discovery of Objects and their Interactions',\n",
       " 'Generative Models of Visually Grounded Imagination',\n",
       " 'Few-shot Autoregressive Density Estimation: Towards Learning to Learn Distributions',\n",
       " 'Compositional Obverter Communication Learning from Raw Visual Input',\n",
       " 'SCAN: Learning Hierarchical Compositional Visual Concepts',\n",
       " 'Hierarchical Density Order Embeddings',\n",
       " 'Identifying Analogies Across Domains',\n",
       " 'Emergence of grid-like representations by training recurrent neural networks to perform spatial localization',\n",
       " 'Learning a neural response metric for retinal prosthesis',\n",
       " 'Few-Shot Learning with Graph Neural Networks',\n",
       " 'Semantically Decomposing the Latent Spaces of Generative Adversarial Networks',\n",
       " 'A Framework for the Quantitative Evaluation of Disentangled Representations',\n",
       " 'Meta-Learning for Semi-Supervised Few-Shot Classification',\n",
       " 'A DIRT-T Approach to Unsupervised Domain Adaptation',\n",
       " 'Generalizing Across Domains via Cross-Gradient Training',\n",
       " 'Learning to cluster in order to transfer across domains and tasks',\n",
       " 'Deep Complex Networks',\n",
       " 'Skip Connections Eliminate Singularities',\n",
       " 'Bi-Directional Block Self-Attention for Fast and Memory-Efficient Sequence Modeling',\n",
       " 'Routing Networks: Adaptive Selection of Non-Linear Functions for Multi-Task Learning',\n",
       " 'Wavelet Pooling for Convolutional Neural Networks',\n",
       " 'FearNet: Brain-Inspired Model for Incremental Learning',\n",
       " 'Do GANs learn the distribution? Some Theory and Empirics',\n",
       " 'Towards Reverse-Engineering Black-Box Neural Networks',\n",
       " 'Understanding Deep Neural Networks with Rectified Linear Units',\n",
       " 'Training wide residual networks for deployment using a single bit for each weight',\n",
       " 'Learn to Pay Attention',\n",
       " 'Monotonic Chunkwise Attention',\n",
       " 'Recasting Gradient-Based Meta-Learning as Hierarchical Bayes',\n",
       " \"Don't Decay the Learning Rate, Increase the Batch Size\",\n",
       " 'Kronecker-factored Curvature Approximations for Recurrent Neural Networks',\n",
       " 'Proximal Backpropagation',\n",
       " 'Neumann Optimizer: A Practical Optimization Algorithm for Deep Neural Networks',\n",
       " 'SGD Learns Over-parameterized Networks that Provably Generalize on Linearly Separable Data',\n",
       " 'A PAC-Bayesian Approach to Spectrally-Normalized Margin Bounds for Neural Networks',\n",
       " 'On the importance of single directions for generalization',\n",
       " 'The Implicit Bias of Gradient Descent on Separable Data',\n",
       " 'Many Paths to Equilibrium: GANs Do Not Need to Decrease a Divergence At Every Step',\n",
       " 'Adaptive Dropout with Rademacher Complexity Regularization',\n",
       " 'A Bayesian Perspective on Generalization and Stochastic Gradient Descent',\n",
       " 'Implicit Causal Models for Genome-wide Association Studies',\n",
       " 'Sensitivity and Generalization in Neural Networks: an Empirical Study',\n",
       " 'Regularizing and Optimizing LSTM Language Models',\n",
       " 'DCN+: Mixed Objective And Deep Residual Coattention for Question Answering',\n",
       " 'Word translation without parallel data',\n",
       " 'All-but-the-Top: Simple and Effective Postprocessing for Word Representations',\n",
       " 'Learning General Purpose Distributed Sentence Representations via Large Scale Multi-task Learning',\n",
       " 'Natural Language Inference over Interaction Space',\n",
       " 'Multi-Task Learning for Document Ranking and Query Suggestion',\n",
       " 'Distributed Fine-tuning of Language Models on Private Data',\n",
       " 'Intrinsic Motivation and Automatic Curricula via Asymmetric Self-Play',\n",
       " 'Reinforcement Learning Algorithm Selection',\n",
       " 'Leave no Trace: Learning to Reset for Safe and Autonomous Reinforcement Learning',\n",
       " 'Consequentialist conditional cooperation in social dilemmas with imperfect information',\n",
       " 'Can Neural Networks Understand Logical Entailment?',\n",
       " 'Cascade Adversarial Machine Learning Regularized with a Unified Embedding',\n",
       " 'Mitigating Adversarial Effects Through Randomization',\n",
       " 'Decision Boundary Analysis of Adversarial Examples',\n",
       " 'Matrix capsules with EM routing',\n",
       " 'CausalGAN: Learning Causal Implicit Generative Models with Adversarial Training',\n",
       " 'Learning Wasserstein Embeddings',\n",
       " 'TRAINING GENERATIVE ADVERSARIAL NETWORKS VIA PRIMAL-DUAL SUBGRADIENT METHODS: A LAGRANGIAN PERSPECTIVE ON GAN',\n",
       " 'Activation Maximization Generative Adversarial Nets',\n",
       " 'Coulomb GANs: Provably Optimal Nash Equilibria via Potential Fields',\n",
       " 'Improving the Improved Training of Wasserstein GANs: A Consistency Term and Its Dual Effect',\n",
       " 'FusionNet: Fusing via Fully-aware Attention with Application to Machine Comprehension',\n",
       " 'Neural Language Modeling by Jointly Learning Syntax and Lexicon',\n",
       " 'Learning Intrinsic Sparse Structures within Long Short-Term Memory',\n",
       " 'Deep Active Learning for Named Entity Recognition',\n",
       " 'Go for a Walk and Arrive at the Answer: Reasoning Over Paths in Knowledge Bases using Reinforcement Learning',\n",
       " 'No Title',\n",
       " 'Lifelong Learning with Dynamically Expandable Networks',\n",
       " 'The Role of Minimal Complexity Functions in Unsupervised Learning of Semantic Mappings',\n",
       " 'Dynamic Neural Program Embeddings for Program Repair',\n",
       " 'Compositional Attention Networks for Machine Reasoning',\n",
       " 'Beyond Shared Hierarchies: Deep Multitask Learning through Soft Layer Ordering',\n",
       " 'Hierarchical Representations for Efficient Architecture Search',\n",
       " 'Reinforcement Learning on Web Interfaces using Workflow-Guided Exploration',\n",
       " 'Combining Symbolic Expressions and Black-box Function Evaluations in Neural Programs',\n",
       " 'Scalable Private Learning with PATE',\n",
       " 'Active Learning for Convolutional Neural Networks: A Core-Set Approach',\n",
       " 'Loss-aware Weight Quantization of Deep Networks',\n",
       " 'Global Optimality Conditions for Deep Neural Networks',\n",
       " 'SpectralNet: Spectral Clustering using Deep Neural Networks',\n",
       " 'Not-So-Random Features',\n",
       " 'Learning how to explain neural networks: PatternNet and PatternAttribution',\n",
       " 'Detecting Statistical Interactions from Neural Network Weights',\n",
       " 'Deep Gaussian Embedding of Graphs: Unsupervised Inductive Learning via Ranking',\n",
       " 'Generating Natural Adversarial Examples',\n",
       " 'Spatially Transformed Adversarial Examples',\n",
       " 'Predicting Floor-Level for 911 Calls with Neural Networks and Smartphone Sensor Data',\n",
       " 'Understanding image motion with group representations',\n",
       " 'Learning Awareness Models',\n",
       " 'Backpropagation through the Void: Optimizing control variates for black-box gradient estimation',\n",
       " 'On Unifying Deep Generative Models',\n",
       " 'Debiasing Evidence Approximations: On Importance-weighted Autoencoders and Jackknife Variational Inference',\n",
       " 'Learning a Generative Model for Validity in Complex Discrete Structures',\n",
       " 'Boundary Seeking GANs',\n",
       " 'Learning Sparse Latent Representations with the Deep Copula Information Bottleneck',\n",
       " 'WHAI: Weibull Hybrid Autoencoding Inference for Deep Topic Modeling',\n",
       " 'Understanding Short-Horizon Bias in Stochastic Meta-Optimization',\n",
       " 'Self-ensembling for visual domain adaptation',\n",
       " 'Gradient Estimators for Implicit Models',\n",
       " 'Learning to Multi-Task by Active Sampling',\n",
       " 'Learning Robust Rewards with Adverserial Inverse Reinforcement Learning',\n",
       " 'A Simple Neural Attentive Meta-Learner',\n",
       " 'Deep Learning and Quantum Entanglement: Fundamental Connections with Implications to Network Design',\n",
       " 'Towards Synthesizing Complex Programs From Input-Output Examples',\n",
       " 'Expressive power of recurrent neural networks',\n",
       " 'Improving the Universality and Learnability of Neural Programmer-Interpreters with Combinator Abstraction',\n",
       " 'An image representation based convolutional network for DNA classification',\n",
       " 'SMASH: One-Shot Model Architecture Search through HyperNetworks',\n",
       " 'Parameter Space Noise for Exploration',\n",
       " 'Synthesizing realistic neural population activity patterns using Generative Adversarial Networks',\n",
       " 'Auto-Encoding Sequential Monte Carlo',\n",
       " 'Learning to Teach',\n",
       " 'PixelNN: Example-based Image Synthesis',\n",
       " 'Non-Autoregressive Neural Machine Translation',\n",
       " 'Deep Voice 3: Scaling Text-to-Speech with Convolutional Sequence Learning',\n",
       " 'mixup: Beyond Empirical Risk Minimization',\n",
       " 'TD or not TD: Analyzing the Role of Temporal Differencing in Deep Reinforcement Learning',\n",
       " 'DORA The Explorer: Directed Outreaching Reinforcement Action-Selection',\n",
       " 'Temporal Difference Models: Model-Free Deep RL for Model-Based Control',\n",
       " 'TreeQN and ATreeC: Differentiable Tree-Structured Models for Deep Reinforcement Learning',\n",
       " 'Alternating Multi-bit Quantization for Recurrent Neural Networks',\n",
       " 'Residual Loss Prediction: Reinforcement Learning With No Incremental Feedback',\n",
       " 'Adaptive Quantization of Neural Networks',\n",
       " 'Boosting the Actor with Dual Critic',\n",
       " 'Guide Actor-Critic for Continuous Control',\n",
       " 'Policy Optimization by Genetic Distillation',\n",
       " 'When is a Convolutional Filter Easy to Learn?',\n",
       " 'Online Learning Rate Adaptation with Hypergradient Descent',\n",
       " 'Stochastic gradient descent performs variational inference, converges to limit cycles for deep networks',\n",
       " 'Robustness of Classifiers to Universal Perturbations: A Geometric Perspective',\n",
       " 'On the regularization of Wasserstein GANs',\n",
       " 'Eigenoption Discovery through the Deep Successor Representation',\n",
       " 'Neural Map: Structured Memory for Deep Reinforcement Learning',\n",
       " 'Active Neural Localization',\n",
       " 'Overcoming Catastrophic Interference using Conceptor-Aided Backpropagation',\n",
       " 'Memory Augmented Control Networks',\n",
       " 'Progressive Reinforcement Learning with Distillation for Multi-Skilled Motion Control',\n",
       " 'N2N learning: Network to Network Compression via Policy Gradient Reinforcement Learning',\n",
       " 'Hierarchical and Interpretable Skill Acquisition in Multi-task Reinforcement Learning',\n",
       " 'Divide-and-Conquer Reinforcement Learning',\n",
       " 'A Compressed Sensing View of Unsupervised Text Embeddings, Bag-of-n-Grams, and LSTMs',\n",
       " 'A New Method of Region Embedding for Text Classification',\n",
       " 'Fix your classifier: the marginal value of training the last weight layer',\n",
       " 'Multi-Mention Learning for Reading Comprehension with Neural Cascades',\n",
       " 'Deep Sensing: Active Sensing using Multi-directional Recurrent Neural Networks',\n",
       " 'Temporally Efficient Deep Learning with Spikes',\n",
       " 'Variational Network Quantization',\n",
       " 'Training GANs with Optimism',\n",
       " 'Sobolev GAN',\n",
       " 'Learning From Noisy Singly-labeled Data',\n",
       " 'Learning Sparse Neural Networks through L_0 Regularization',\n",
       " 'Variational Continual Learning',\n",
       " 'Gaussian Process Behaviour in Wide Deep Neural Networks',\n",
       " 'Mixed Precision Training of Convolutional Neural Networks using Integer Operations',\n",
       " 'Memory Architectures in Recurrent Neural Network Language Models',\n",
       " 'On the Information Bottleneck Theory of Deep Learning',\n",
       " 'On the Convergence of Adam and Beyond',\n",
       " 'Synthetic and Natural Noise Both Break Neural Machine Translation',\n",
       " 'Multi-Scale Dense Networks for Resource Efficient Image Classification',\n",
       " 'Training and Inference with Integers in Deep Neural Networks',\n",
       " 'Emergence of Linguistic Communication from  Referential Games with Symbolic and Pixel Input',\n",
       " 'Spherical CNNs',\n",
       " 'Ask the Right Questions: Active Question Reformulation with Reinforcement Learning',\n",
       " 'On the insufficiency of existing momentum schemes for Stochastic Optimization',\n",
       " 'Certifying Some Distributional Robustness with Principled Adversarial Training',\n",
       " 'Learning Deep Mean Field Games for Modeling Large Population Behavior',\n",
       " 'Wasserstein Auto-Encoders',\n",
       " 'Spectral Normalization for Generative Adversarial Networks',\n",
       " 'Learning to Represent Programs with Graphs',\n",
       " 'Characterizing Adversarial Subspaces Using Local Intrinsic Dimensionality',\n",
       " 'Breaking the Softmax Bottleneck: A High-Rank RNN Language Model',\n",
       " 'Continuous Adaptation via Meta-Learning in Nonstationary and Competitive Environments',\n",
       " 'Boosting Dilated Convolutional Networks with Mixed Tensor Decompositions',\n",
       " 'Neural Sketch Learning for Conditional Program Generation',\n",
       " 'Progressive Growing of GANs for Improved Quality, Stability, and Variation',\n",
       " 'Variance Reduction for Policy Gradient with Action-Dependent Factorized Baselines',\n",
       " 'Zero-Shot Visual Imitation',\n",
       " 'Beyond Word Importance:  Contextual Decomposition to Extract Interactions from LSTMs',\n",
       " 'AmbientGAN: Generative models from lossy measurements',\n",
       " 'Making Neural Programming Architectures Generalize via Recursion',\n",
       " 'End-to-end Optimized Image Compression',\n",
       " 'Optimization as a Model for Few-Shot Learning',\n",
       " 'Learning End-to-End Goal-Oriented Dialog',\n",
       " 'Towards Principled Methods for Training Generative Adversarial Networks',\n",
       " 'Reinforcement Learning with Unsupervised Auxiliary Tasks',\n",
       " 'Multi-Agent Cooperation and the Emergence of (Natural) Language',\n",
       " 'Understanding deep learning requires rethinking generalization',\n",
       " 'Neural Architecture Search with Reinforcement Learning',\n",
       " 'Q-Prop: Sample-Efficient Policy Gradient with An Off-Policy Critic',\n",
       " 'Learning to Act by Predicting the Future',\n",
       " 'On Large-Batch Training for Deep Learning: Generalization Gap and Sharp Minima',\n",
       " 'Semi-supervised Knowledge Transfer for Deep Learning from Private Training Data',\n",
       " 'Amortised MAP Inference for Image Super-resolution',\n",
       " 'Learning Graphical State Transitions',\n",
       " 'Maximum Entropy Flow Networks',\n",
       " 'Topology and Geometry of Half-Rectified Network Optimization',\n",
       " 'Paying More Attention to Attention: Improving the Performance of Convolutional Neural Networks via Attention Transfer',\n",
       " 'Learning Visual Servoing with Deep Features and Fitted Q-Iteration',\n",
       " 'Stochastic Neural Networks for Hierarchical Reinforcement Learning',\n",
       " 'Nonparametric Neural Networks',\n",
       " 'Distributed Second-Order Optimization using Kronecker-Factored Approximations',\n",
       " 'Pruning Filters for Efficient ConvNets',\n",
       " 'Learning to Generate Samples from Noise through Infusion Training',\n",
       " 'FILTER SHAPING FOR CONVOLUTIONAL NEURAL NETWORKS',\n",
       " 'Normalizing the Normalizers: Comparing and Extending Network Normalization Schemes',\n",
       " 'Multilayer Recurrent Network Models of Primate Retinal Ganglion Cell Responses',\n",
       " 'Improving Generative Adversarial Networks with Denoising Feature Matching',\n",
       " 'Efficient Vector Representation for Documents through Corruption',\n",
       " 'Learning Invariant Feature Spaces to Transfer Skills with Reinforcement Learning',\n",
       " 'Transfer of View-manifold Learning to Similarity Perception of Novel Objects',\n",
       " 'What does it take to generate natural textures?',\n",
       " 'Emergence of foveal image sampling from learning to attend in visual scenes',\n",
       " 'An Information-Theoretic Framework for Fast and Robust Unsupervised Learning via Neural Population Infomax',\n",
       " 'PixelCNN++: Improving the PixelCNN with Discretized Logistic Mixture Likelihood and Other Modifications',\n",
       " 'Mode Regularized Generative Adversarial Networks',\n",
       " 'Highway and Residual Networks learn Unrolled Iterative Estimation',\n",
       " 'Improving Neural Language Models with a Continuous Cache',\n",
       " 'Unsupervised Cross-Domain Image Generation',\n",
       " 'Third Person Imitation Learning',\n",
       " 'Variational Recurrent Adversarial Deep Domain Adaptation',\n",
       " 'Program Synthesis for Character Level Language Modeling',\n",
       " 'Episodic Exploration for Deep Deterministic Policies for StarCraft Micromanagement',\n",
       " 'Soft Weight-Sharing for Neural Network Compression',\n",
       " 'Neural Program Lattices',\n",
       " 'Tracking the World State with Recurrent Entity Networks',\n",
       " 'Steerable CNNs',\n",
       " 'Learning to Query, Reason, and Answer Questions On Ambiguous Texts',\n",
       " 'Deep Predictive Coding Networks for Video Prediction and Unsupervised Learning',\n",
       " 'Diet Networks: Thin Parameters for Fat Genomics',\n",
       " 'Deep Biaffine Attention for Neural Dependency Parsing',\n",
       " 'PixelVAE: A Latent Variable Model for Natural Images',\n",
       " 'Snapshot Ensembles: Train 1, Get M for Free',\n",
       " 'Training Agent for First-Person Shooter Game with Actor-Critic Curriculum Learning',\n",
       " 'Neuro-Symbolic Program Synthesis',\n",
       " 'Decomposing Motion and Content for Natural Video Sequence Prediction',\n",
       " 'Towards a Neural Statistician',\n",
       " 'Generative Models and Model Criticism via Optimized Maximum Mean Discrepancy',\n",
       " 'Generalizing Skills with Semi-Supervised Reinforcement Learning',\n",
       " 'Learning Curve Prediction with Bayesian Neural Networks',\n",
       " 'Learning to Optimize',\n",
       " 'A Compare-Aggregate Model for Matching Text Sequences',\n",
       " 'Data Noising as Smoothing in Neural Network Language Models',\n",
       " 'Training Compressed Fully-Connected Networks with a Density-Diversity Penalty',\n",
       " 'Autoencoding Variational Inference For Topic Models',\n",
       " 'Optimal Binary Autoencoding with Pairwise Correlations',\n",
       " 'On the Quantitative Analysis of Decoder-Based Generative Models',\n",
       " 'Trained Ternary Quantization',\n",
       " 'DSD: Dense-Sparse-Dense Training for Deep Neural Networks',\n",
       " 'A Compositional Object-Based Approach to Learning Physical Dynamics',\n",
       " 'Learning to Remember Rare Events',\n",
       " 'Transfer Learning for Sequence Tagging with Hierarchical Recurrent Networks',\n",
       " 'Words or Characters? Fine-grained Gating for Reading Comprehension',\n",
       " 'A Simple but Tough-to-Beat Baseline for Sentence Embeddings',\n",
       " 'Capacity and Trainability in Recurrent Neural Networks',\n",
       " 'Learning to Perform Physics Experiments via Deep Reinforcement Learning',\n",
       " 'Improving Policy Gradient by Exploring Under-appreciated Rewards',\n",
       " 'Deep Learning with Dynamic Computation Graphs',\n",
       " 'Calibrating Energy-based Generative Adversarial Networks',\n",
       " 'Pruning Convolutional Neural Networks for Resource Efficient Inference',\n",
       " 'Query-Reduction Networks for Question Answering',\n",
       " 'Designing Neural Network Architectures using Reinforcement Learning',\n",
       " 'Machine Comprehension Using Match-LSTM and Answer Pointer',\n",
       " 'DeepDSL: A Compilation-based Domain-Specific Language for Deep Learning',\n",
       " 'Bidirectional Attention Flow for Machine Comprehension',\n",
       " 'Incorporating long-range consistency in CNN-based texture generation',\n",
       " 'Dynamic Coattention Networks For Question Answering',\n",
       " 'SampleRNN: An Unconditional End-to-End Neural Audio Generation Model',\n",
       " 'Metacontrol for Adaptive Imagination-Based Optimization',\n",
       " 'Exploring Sparsity in Recurrent Neural Networks',\n",
       " 'Lossy Image Compression with Compressive Autoencoders',\n",
       " 'Structured Attention Networks',\n",
       " 'Zoneout: Regularizing RNNs by Randomly Preserving Hidden Activations',\n",
       " 'Deep Probabilistic Programming',\n",
       " 'LR-GAN: Layered Recursive Generative Adversarial Networks for Image Generation',\n",
       " 'Variational Lossy Autoencoder',\n",
       " 'A recurrent neural network without chaos',\n",
       " 'Outrageously Large Neural Networks: The Sparsely-Gated Mixture-of-Experts Layer',\n",
       " 'Tree-structured decoding with doubly-recurrent neural networks',\n",
       " 'Introspection:Accelerating Neural Network Training By Learning Weight Evolution',\n",
       " 'Hyperband: Bandit-Based Configuration Evaluation for Hyperparameter Optimization',\n",
       " 'Lie-Access Neural Turing Machines',\n",
       " 'Quasi-Recurrent Neural Networks',\n",
       " 'Recurrent Environment Simulators',\n",
       " 'EPOpt: Learning Robust Neural Network Policies Using Model Ensembles',\n",
       " 'Attend, Adapt and Transfer: Attentive Deep Architecture for Adaptive Transfer from multiple sources in the same domain',\n",
       " 'Multi-view Recurrent Neural Acoustic Word Embeddings',\n",
       " 'Learning Features of Music From Scratch',\n",
       " 'A Baseline for Detecting Misclassified and Out-of-Distribution Examples in Neural Networks',\n",
       " 'Learning to superoptimize programs',\n",
       " 'Trusting SVM for Piecewise Linear CNNs',\n",
       " 'Sigma Delta Quantized Networks',\n",
       " 'A STRUCTURED SELF-ATTENTIVE SENTENCE EMBEDDING',\n",
       " 'Regularizing CNNs with Locally Constrained Decorrelations',\n",
       " 'The Concrete Distribution: A Continuous Relaxation of Discrete Random Variables',\n",
       " 'Unrolled Generative Adversarial Networks',\n",
       " 'TopicRNN: A Recurrent Neural Network with Long-Range Semantic Dependency',\n",
       " 'Frustratingly Short Attention Spans in Neural Language Modeling',\n",
       " 'Recurrent Hidden Semi-Markov Model',\n",
       " 'Deep Variational Bayes Filters: Unsupervised Learning of State Space Models from Raw Data',\n",
       " 'Generative Multi-Adversarial Networks',\n",
       " 'Mollifying Networks',\n",
       " 'beta-VAE: Learning Basic Visual Concepts with a Constrained Variational Framework',\n",
       " 'Offline bilingual word vectors, orthogonal transformations and the inverted softmax',\n",
       " 'Visualizing Deep Neural Network Decisions: Prediction Difference Analysis',\n",
       " 'Categorical Reparameterization with Gumbel-Softmax',\n",
       " 'Online Bayesian Transfer Learning for Sequential Data Modeling',\n",
       " 'Latent Sequence Decompositions',\n",
       " 'Paleo: A Performance Model for Deep Neural Networks',\n",
       " 'Combining policy gradient and Q-learning',\n",
       " 'Density estimation using Real NVP',\n",
       " 'Recurrent Batch Normalization',\n",
       " 'SGDR: Stochastic Gradient Descent with Warm Restarts',\n",
       " 'Learning a Natural Language Interface with Neural Programmer',\n",
       " 'Reinforcement Learning through Asynchronous Advantage Actor-Critic on a GPU',\n",
       " 'Learning to Navigate in Complex Environments',\n",
       " 'DeepCoder: Learning to Write Programs',\n",
       " 'Learning and Policy Search in Stochastic Dynamical Systems with Bayesian Neural Networks',\n",
       " 'Variable Computation in Recurrent Neural Networks',\n",
       " 'Deep Variational Information Bottleneck',\n",
       " 'The Neural Noisy Channel',\n",
       " 'Automatic Rule Extraction from Long Short Term Memory Networks',\n",
       " 'Dialogue Learning With Human-in-the-Loop',\n",
       " 'Adversarially Learned Inference',\n",
       " 'Learning through Dialogue Interactions by Asking Questions',\n",
       " 'Deep Information Propagation',\n",
       " 'FractalNet: Ultra-Deep Neural Networks without Residuals',\n",
       " 'Revisiting Classifier Two-Sample Tests',\n",
       " 'Learning to Repeat: Fine Grained Action Repetition for Deep Reinforcement Learning',\n",
       " 'Loss-aware Binarization of Deep Networks',\n",
       " 'Learning to Play in a Day: Faster Deep Reinforcement Learning by Optimality Tightening',\n",
       " 'Energy-based Generative Adversarial Networks',\n",
       " 'Central Moment Discrepancy (CMD) for Domain-Invariant Representation Learning',\n",
       " 'Incremental Network Quantization: Towards Lossless CNNs with Low-precision Weights',\n",
       " 'Entropy-SGD: Biasing Gradient Descent Into Wide Valleys',\n",
       " 'Deep Multi-task Representation Learning: A Tensor Factorisation Approach',\n",
       " 'Sample Efficient Actor-Critic with  Experience Replay',\n",
       " 'Temporal Ensembling for Semi-Supervised Learning',\n",
       " 'On Detecting Adversarial Perturbations',\n",
       " 'Training deep neural-networks using a noise adaptation layer',\n",
       " 'Learning to Compose Words into Sentences with Reinforcement Learning',\n",
       " 'Delving into Transferable Adversarial Examples and Black-box Attacks',\n",
       " 'Identity Matters in Deep Learning',\n",
       " 'Adversarial Feature Learning',\n",
       " 'Towards the Limit of Network Quantization',\n",
       " 'Faster CNNs with Direct Sparse Convolutions and Guided Pruning',\n",
       " 'Stick-Breaking Variational Autoencoders',\n",
       " 'Batch Policy Gradient  Methods for  Improving Neural Conversation Models',\n",
       " 'Support Regularized Sparse Coding and Its Fast Encoder',\n",
       " 'Tying Word Vectors and Word Classifiers: A Loss Framework for Language Modeling',\n",
       " 'Towards Deep Interpretability (MUS-ROVER II): Learning Hierarchical Representations of Tonal Music',\n",
       " 'Discrete Variational Autoencoders',\n",
       " 'Do Deep Convolutional Nets Really Need to be Deep and Convolutional?',\n",
       " 'Geometry of Polysemy',\n",
       " 'Learning Invariant Representations Of Planar Curves',\n",
       " 'Reasoning with Memory Augmented Neural Networks for Language Comprehension',\n",
       " 'Learning Recurrent Representations for Hierarchical Behavior Modeling',\n",
       " 'Adversarial Machine Learning at Scale',\n",
       " 'Predicting Medications from Diagnostic Codes with Recurrent Neural Networks',\n",
       " 'Recurrent Mixture Density Network for Spatiotemporal Visual Attention',\n",
       " 'Inductive Bias of Deep Convolutional Networks through Pooling Geometry',\n",
       " 'Efficient Representation of Low-Dimensional Manifolds using Deep Networks',\n",
       " 'Semi-Supervised Classification with Graph Convolutional Networks',\n",
       " 'Sparsely-Connected Neural Networks: Towards Efficient VLSI Implementation of Deep Neural Networks',\n",
       " 'Adversarial Training Methods for Semi-Supervised Text Classification',\n",
       " 'Fine-grained Analysis of Sentence Embeddings Using Auxiliary Prediction Tasks',\n",
       " 'Pointer Sentinel Mixture Models',\n",
       " 'An Actor-Critic Algorithm for Sequence Prediction',\n",
       " 'Understanding Trainable Sparse Coding with Matrix Factorization',\n",
       " 'Tighter bounds lead to improved classifiers',\n",
       " 'HolStep: A Machine Learning Dataset for Higher-order Logic Theorem Proving',\n",
       " 'Why Deep Neural Networks for Function Approximation?',\n",
       " 'Hierarchical Multiscale Recurrent Neural Networks',\n",
       " 'Neural Photo Editing with Introspective Adversarial Networks',\n",
       " 'Dropout with Expectation-linear Regularization',\n",
       " 'HyperNetworks',\n",
       " 'A Learned Representation For Artistic Style',\n",
       " 'Hadamard Product for Low-rank Bilinear Pooling',\n",
       " 'Learning Continuous Semantic Representations of Symbolic Expressions',\n",
       " 'Discovering objects and their relations from entangled scene representations',\n",
       " 'Towards an automatic Turing test: Learning to evaluate dialogue responses',\n",
       " 'Gated Multimodal Units for Information Fusion',\n",
       " 'Unsupervised Perceptual Rewards for Imitation Learning',\n",
       " 'A Theoretical Framework for Robustness of (Deep) Classifiers against Adversarial Samples',\n",
       " 'Lifelong Perceptual Programming By Example',\n",
       " 'Automated Generation of Multilingual Clusters for the Evaluation of Distributed Representations',\n",
       " 'Shift Aggregate Extract Networks',\n",
       " 'Programming With a Differentiable Forth Interpreter',\n",
       " 'Bit-Pragmatic Deep Neural Network Computing',\n",
       " 'Recursive Regression with Neural Networks: Approximating the HJI PDE Solution',\n",
       " 'Nonparametrically Learning Activation Functions in Deep Neural Nets',\n",
       " 'Generalizable Features From Unsupervised Learning',\n",
       " 'Deep Learning with Sets and Point Clouds',\n",
       " 'Exponential Machines',\n",
       " 'Song From PI: A Musically Plausible Network for Pop Music Generation',\n",
       " 'Learning to Discover Sparse Graphical Models',\n",
       " 'Learning to Draw Samples: With Application to Amortized MLE for Generative Adversarial Learning',\n",
       " 'Recurrent Normalization Propagation',\n",
       " 'Generating Interpretable Images with Controllable Structure',\n",
       " 'Fast Chirplet Transform to Enhance CNN Machine Listening - Validation on Animal calls and Speech',\n",
       " 'Symmetry-Breaking Convergence Analysis of Certain Two-layered Neural Networks with ReLU nonlinearity',\n",
       " 'Efficient Softmax Approximation for GPUs',\n",
       " 'Dataset Augmentation in Feature Space',\n",
       " 'Online Structure Learning for Sum-Product Networks with Gaussian Leaves',\n",
       " 'Neural Taylor Approximations: Convergence and Exploration in Rectifier Networks',\n",
       " 'Multiplicative LSTM for sequence modelling',\n",
       " 'Neural Functional Programming',\n",
       " 'Tuning Recurrent Neural Networks with Reinforcement Learning',\n",
       " 'Perception Updating Networks: On architectural constraints for interpretable video generative models',\n",
       " 'Neural Data Filter for Bootstrapping Stochastic Gradient Descent',\n",
       " 'Surprise-Based Intrinsic Motivation for Deep Reinforcement Learning',\n",
       " 'Learning in Implicit Generative Models',\n",
       " 'Adaptive Feature Abstraction for Translating Video to Language',\n",
       " 'On Robust Concepts and Small Neural Nets',\n",
       " 'RenderGAN: Generating Realistic Labeled Data',\n",
       " 'Semi-supervised deep learning by metric embedding',\n",
       " 'Modularized Morphing of Neural Networks',\n",
       " 'Short and Deep: Sketching and Neural Networks',\n",
       " 'Modular Multitask Reinforcement Learning with Policy Sketches',\n",
       " 'Development of JavaScript-based deep learning platform and application to distributed training',\n",
       " 'A Differentiable Physics Engine for Deep Learning in Robotics',\n",
       " 'Compositional Kernel Machines',\n",
       " 'Extrapolation and learning equations',\n",
       " 'Adversarial examples in the physical world',\n",
       " 'Charged Point Normalization: An Efficient Solution to the Saddle Point Problem']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(a1))\n",
    "print(len(a2))\n",
    "a1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = pd.Series(a1)\n",
    "s2 = pd.Series(a2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1.to_excel(\"ICLR_accepted1.xlsx\", encoding='utf-8')\n",
    "s2.to_excel(\"ICLR_rejected1.xlsx\", encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
